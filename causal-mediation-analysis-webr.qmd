---
title: A Tutorial on Conducting Mediation Analysis with Exposure Mixtures
filters:
  - webr
---

## Load libraries required for this document

```{webr-r}
library(tidyverse)
# library(bkmr) bkmr is not available on webR
# library(CMAverse) CMAverse is not available on webR

# Can compile unavailable R packages to an R WASM Package binary and setup a custom repository to share it (r-universe.dev)
```


## Example: Simulation Data

### Setup code

```{webr-r}
p <- 1; q <- 30; s <- 6

# Indirect effects
Alpha_a <- matrix(0, nrow = 1, ncol = q)
Alpha_a[c(1, 11, 21)] <- 1 # weak effect
Alpha_a[c(2, 12, 22)] <- 4 # moderate effect
Alpha_a[c(3, 13, 23)] <- 8 # strong effect

Beta_m <- 0.5

# Direct effects
Beta_a <- rep(c(5, 0, 0), times = q/3) %>% as.matrix()

# Confounder effects
Theta_c <- matrix(rep(0.1, times = q*(s-1)), nrow = q)
Alpha_c <- matrix(1, nrow = p, ncol = s)
Beta_c <- matrix(1, nrow = s, ncol = 1)
```


### Data Generation

```{webr-r}
# Function that generates data
data_gen <- function(n_obs, n_expo, n_confound,
                     expo_blockNum, expo_blockCorr,
                     confound_blockNum, confound_blockCorr,
                     Alpha_a, Alpha_c, Beta_m, Beta_a, Beta_c,
                     Theta_c, # theta_c is what confounders contributes to exposures (q times s dim)
                     adjR2_M, adjR2_Y){
  n_obs <- n_obs
  q <- n_expo
  p <- 1 # we assume 1 mediator for now
  # We assume no confounders
  s <- n_confound + 1 # if s == 1 then it is just the intercept
  
  # Geenrate intercept and confounders
  if(s == 1){
    C_i_T <- rep(1, n_obs) %>% as.matrix() 
    Sigma_C <- diag(s)
  } else{
    interCept <- rep(1, n_obs) %>% as.matrix() 
    
    Sigma_C <- gen_block_corr(exposure_numbers = confound_blockNum,
                              correlations = confound_blockCorr)
    
    conFound <- MASS::mvrnorm(n = n_obs, mu = rep(0, s-1), Sigma = Sigma_C) # s is the number of confounders
    C_i_T <- cbind(interCept, conFound)
  }
  
  ## Exposures
  Sigma_X <- gen_block_corr(exposure_numbers = expo_blockNum,
                            correlations = expo_blockCorr)
  
  # generate the exposures
  X <- t(Theta_c %*% t(conFound)) + MASS::mvrnorm(n = n_obs, mu = rep(0, q), Sigma = Sigma_X) #  MASS::mvrnorm(n = n_obs, mu = rep(0, q), Sigma = Sigma_X)
  colnames(X) <- paste0("x", 1: q)
  
  # we can calculate the Sigma_M (a scalar here)
  adjR2_M <- adjR2_M
  r2_M <- 1 - ((n_obs - q - s - 1)/(n_obs - 1))*(1 - adjR2_M) # set adjusted r-squared to 0.3
  
  
  # some prep
  big_alpha <- cbind(Alpha_a, Alpha_c)
  colnames(big_alpha) <- NULL
  
  V_mat_alpha <- matrix(0, nrow = (q+s), ncol = (q+s))
  V_mat_alpha[1:q, 1:q] <- var(X)
  V_mat_alpha[(q+1):(q+s), (q+1):(q+s)] <- var(C_i_T)
  
  
  Sigma_M <- ((1-r2_M)/(r2_M))*big_alpha %*% V_mat_alpha %*% t(big_alpha)
  
  # Generate M Mediators
  M <- t(Alpha_a %*% t(X) + Alpha_c %*% t(C_i_T)) + MASS::mvrnorm(n = n_obs, mu = 0, Sigma = Sigma_M) # mu + error
  
  #Generate sigma^2_e (error variance of the outcome model)
  # big_beta
  big_bt <- cbind(Beta_m, t(Beta_a), t(Beta_c))
  colnames(big_bt) <- NULL
  
  # build the V = var covar of M, X
  V_mat <- matrix(0, nrow = (p+q+s), ncol = (p+q+s))
  V_mat[1:p, 1:p] <- var(M)
  V_mat[(p+1):(p+q), (p+1):(p+q)] <- var(X) 
  V_mat[(p+q+1):(p+q+s), (p+q+1):(p+q+s)] <- var(C_i_T) 
  
  
  # Calculate the sigma_y
  adjR2_Y <- adjR2_Y
  r2_Y <- 1 - ((n_obs - p - q - s - 1)/(n_obs - 1))*(1 - adjR2_Y) # set adjusted r-squared to 0.3
  
  # calculate the optimal sigma^2_e for the two cases
  Sigma_Y <- ((1-r2_Y)/(r2_Y))*big_bt %*% V_mat %*% t(big_bt)
  
  #Generate Y
  comb_predictors <- cbind(M, X, C_i_T)
  colnames(comb_predictors)[seq(p)] <- paste("m", seq(p))
  colnames(comb_predictors)[p + seq(q)] <- paste("x", seq(q))
  colnames(comb_predictors)[p + q + seq(s)] <- paste(c("intercept", paste("c", seq(s-1))))
  
  # if there are more than one confounders
  #ifelse(s > 1,   colnames(comb_predictors)[p + q + 1 + seq(s)] <- paste("c", seq(s-1)), 
  #      0)
  
  y1 <- t(big_bt %*% t(comb_predictors)) + MASS::mvrnorm(n = n_obs, mu = 0, Sigma = Sigma_Y) # mu + error
  
  #Combine the results
  df_gen <- cbind(y1, M, X, C_i_T) %>% as.data.frame() #%>% dplyr::rename(y = V1, m1 = V2, intercept = V33)
  
  colnames(df_gen) <- c("y", paste0("m", seq(p)), paste0("x", seq(q)), "intercept", paste0("c", seq(s-1)))
  
  return(df_gen)
}

gen_block_corr <- function(exposure_numbers, correlations) {
  if (length(exposure_numbers) != length(correlations)) {
    stop("The lengths of exposure_numbers and correlations must match.")
  }
  
  # Load the Matrix library for bdiag
  if (!requireNamespace("Matrix", quietly = TRUE)) {
    stop("The Matrix package is required. Please install it using install.packages('Matrix')")
  }
  
  # Function to create a single correlation block
  create_correlation_block <- function(size, correlation) {
    block <- matrix(correlation, nrow = size, ncol = size)
    diag(block) <- 1 # Set diagonal elements to 1
    return(block)
  }
  
  # Create each correlation block and store them in a list
  blocks <- lapply(seq_along(exposure_numbers), function(i) {
    create_correlation_block(exposure_numbers[i], correlations[i])
  })
  
  # Combine the blocks into a block diagonal matrix
  correlation_matrix <- Matrix::bdiag(blocks)
  
  # Convert to a regular matrix for compatibility
  correlation_matrix <- as.matrix(correlation_matrix)
  
  return(correlation_matrix)
}
```


### Run simulation

```{webr-r}
set.seed(1211)
df_sim <- data_gen(n_obs = 2000, n_expo = 30, n_confound = 5,
                   expo_blockNum =  c(5, 10, 15),
                   expo_blockCorr = c(0.4, 0.8, 0.1),
                   confound_blockNum = 5, confound_blockCorr = 0.2,
                   Alpha_a = Alpha_a, Alpha_c = Alpha_c, 
                   Beta_m = Beta_m, Beta_a = Beta_a,
                   Beta_c = Beta_c, Theta_c = Theta_c,
                   adjR2_M = 0.3, adjR2_Y = 0.3)
```


## Individual exposure testing (without co-exposure)

### Setup code
```{webr-r}
set.seed(1211)

expo_nm <- df_sim %>%
  select(starts_with("x")) %>%
  colnames()

confounders_nm <- df_sim %>%
  select(starts_with("c")) %>%
  colnames()

mediator_nm <- df_sim %>%
  select(starts_with("m")) %>%
  colnames()

outcome_nm <- "y"
```

### Define IndExpo_medTest_NV()
```{webr-r}
IndExpo_medTest_NV <- function(data, nboot = 1000,
                               exposures_nm, confounders_nm,
                               mediator_nm, outcome_nm) {
  suppressMessages(invisible(lapply(c("CMAverse", "purrr", "rlang"), require, character.only = T)))
  
  # extract the list of exposures
  Expo_names <- exposures_nm
  
  if (length(Expo_names) == 0) {
    stop("There are no columns with names in Expo_names")
  }
  
  # a list to store the results
  medTest_res <- list()
  
  # a function for purrr::map()
  run_cmest <- function(Expo_id, data, nboot,
                        confounders_nm = confounders_nm,
                        mediator_nm = mediator_nm,
                        outcome_nm = outcome_nm) {
    if (length(confounders_nm) == 0) {
      y_formula <- as.formula(paste0(outcome_nm, " ~ ", Expo_id, " + ", mediator_nm))
      m_formula <- as.formula(paste0(mediator_nm, " ~ ", Expo_id))
      
      # Evaluate the formulas in the correct environment
      y_model <- eval(bquote(glm(.(y_formula), family = gaussian, data = data)))
      m_model <- eval(bquote(glm(.(m_formula), family = gaussian, data = data)))
      
      # the CMA mediation effect testing
      suppressWarnings(cma_test <- CMAverse::cmest(
        data = data, model = "rb",
        full = T, EMint = F,
        yreg = y_model,
        mreg = list(m_model),
        mval = list(0),
        outcome = outcome_nm, exposure = Expo_id, mediator = mediator_nm,
        inference = "bootstrap", nboot = nboot, boot.ci.type = "per"
      ))
    } else {
      y_formula <- as.formula(paste0(
        outcome_nm, " ~ ", Expo_id, " + ", mediator_nm,
        " + ", paste0(confounders_nm, collapse = " + ")
      ))
      m_formula <- as.formula(paste0(
        mediator_nm, " ~ ", Expo_id,
        " + ", paste0(confounders_nm, collapse = " + ")
      ))
      
      # Evaluate the formulas in the correct environment
      y_model <- eval(bquote(glm(.(y_formula), family = gaussian, data = data)))
      m_model <- eval(bquote(glm(.(m_formula), family = gaussian, data = data)))
      
      # the CMA mediation effect testing
      suppressWarnings(cma_test <- CMAverse::cmest(
        data = data, model = "rb",
        full = T, EMint = F,
        yreg = y_model,
        mreg = list(m_model),
        mval = list(0), basec = c(confounders_nm),
        outcome = outcome_nm, exposure = Expo_id, mediator = mediator_nm,
        inference = "bootstrap", nboot = nboot, boot.ci.type = "per"
      ))
    }
    
    # tidy a summary table
    summary_table <- cbind(
      cma_test$effect.pe,
      cma_test$effect.se,
      cma_test$effect.ci.low,
      cma_test$effect.ci.high,
      cma_test$effect.pval
    )
    
    colnames(summary_table) <- c("Estimate", "SE", "CI_Low", "CI_Upper", "Pval")
    
    print(paste("     ", Expo_id, "Bootstrap done"))
    
    list(`CMA Test` = cma_test, `CMA Summary Table` = summary_table)
  }
  
  # run the mediation tests over all the exposures
  medTest_res <- purrr::map(Expo_names, ~ run_cmest(
    .x, data, nboot,
    confounders_nm,
    mediator_nm, outcome_nm
  ))
  names(medTest_res) <- Expo_names
  return(medTest_res)
}
```


### Run IndExpo_medTest_NV()

```{webr-r}
result <- IndExpo_medTest_NV(
  data = df_sim,
  nboot = 1000,
  exposures_nm = expo_nm,
  mediator_nm = mediator_nm,
  outcome_nm = outcome_nm,
  confounders_nm = confounders_nm
)
```


## Individual exposure testing (with co-exposure)

### Define IndExpo_medTest()

```{webr-r}
IndExpo_medTest <- function(data, nboot = 1000,
                            exposures_nm, confounders_nm,
                            mediator_nm, outcome_nm){
  
  suppressMessages(invisible(lapply(c("CMAverse", "purrr", "rlang"), require, character.only = T)))
  
  # extract the list of exposures
  Expo_names <- exposures_nm
  
  if(length(Expo_names) == 0){
    stop('There are no columns with names in Expo_names')
  }
  
  # a list to store the results
  medTest_res <- list()
  
  # a function for purrr::map()
  run_cmest <- function(Expo_id, data, nboot,
                        confounders_nm = confounders_nm,
                        mediator_nm = mediator_nm,
                        outcome_nm = outcome_nm) {
    
    if(length(confounders_nm) == 0){
      y_formula <- as.formula(paste0(outcome_nm, " ~ ", Expo_id, " + ",
                                     mediator_nm, " + ",
                                     paste0(Expo_names[Expo_names != Expo_id], collapse = " + ")))
      
      m_formula <- as.formula(paste0(mediator_nm, " ~ ", Expo_id, " + ", 
                                     paste0(Expo_names[Expo_names != Expo_id], collapse = " + ")))
      
      # Evaluate the formulas in the correct environment
      y_model <- eval(bquote(glm(.(y_formula), family = gaussian, data = data)))
      m_model <- eval(bquote(glm(.(m_formula), family = gaussian, data = data)))
      
      # the CMA mediation effect testing
      suppressWarnings(cma_test <- CMAverse::cmest(data = data, model = "rb",
                                                   full = T, EMint = F,
                                                   yreg = y_model, 
                                                   mreg = list(m_model),
                                                   mval = list(0),
                                                   basec = c(Expo_names[Expo_names != Expo_id]),
                                                   outcome = outcome_nm,
                                                   exposure = Expo_id,
                                                   mediator = mediator_nm,
                                                   inference = "bootstrap", nboot = nboot,
                                                   boot.ci.type = "per"))
    } else {
      y_formula <- as.formula(paste0(outcome_nm, " ~ ", Expo_id, " + ", mediator_nm, " + ",
                                     paste0(Expo_names[Expo_names != Expo_id], collapse = " + "),
                                     " + ", paste0(confounders_nm, collapse = " + ")))
      
      m_formula <- as.formula(paste0(mediator_nm, " ~ ", Expo_id, " + ",
                                     paste0(Expo_names[Expo_names != Expo_id], collapse = " + "),
                                     " + ", paste0(confounders_nm, collapse = " + ")))
      
      # Evaluate the formulas in the correct environment
      y_model <- eval(bquote(glm(.(y_formula), family = gaussian, data = data)))
      m_model <- eval(bquote(glm(.(m_formula), family = gaussian, data = data)))
      
      # the CMA mediation effect testing
      suppressWarnings(cma_test <- CMAverse::cmest(data = data, model = "rb",
                                                   full = T, EMint = F,
                                                   yreg = y_model, 
                                                   mreg = list(m_model),
                                                   mval = list(0),
                                                   basec = c(Expo_names[Expo_names != Expo_id], confounders_nm),
                                                   outcome = outcome_nm,
                                                   exposure = Expo_id, 
                                                   mediator = mediator_nm,
                                                   inference = "bootstrap",
                                                   nboot = nboot, boot.ci.type = "per"))
    }
    
    # tidy a summary table
    summary_table <- cbind(cma_test$effect.pe,
                           cma_test$effect.se,
                           cma_test$effect.ci.low,
                           cma_test$effect.ci.high,
                           cma_test$effect.pval)
    
    colnames(summary_table) <- c("Estimate", "SE", "CI_Low", "CI_Upper", "Pval")
    
    print(paste("     ", Expo_id, "Bootstrap done"))
    
    list(`CMA Test` = cma_test, `CMA Summary Table` = summary_table)
  }
  
  # run the mediation tests over all the exposures
  medTest_res <- purrr::map(Expo_names, ~run_cmest(.x, data, nboot,
                                                   confounders_nm,
                                                   mediator_nm, outcome_nm))
  names(medTest_res) <- Expo_names
  return(medTest_res)
}
```


### Run IndExpo_medTest()

```{webr-r}
set.seed(1211)
expo_nm <- df_sim %>% select(starts_with("x")) %>% colnames()
confounders_nm <- df_sim %>% select(starts_with("c")) %>% colnames()
mediator_nm <- df_sim %>% select(starts_with("m")) %>% colnames()
outcome_nm <- "y"	

result <- IndExpo_medTest(data = df_sim,
                          nboot = 1000,
                          exposures_nm = expo_nm,
                          mediator_nm = mediator_nm,
                          outcome_nm = outcome_nm,
                          confounders_nm = confounders_nm)
```



## Principal component analysis

```{webr-r}
set.seed(1211)
df_expo <- df_sim %>% dplyr::select(contains("x"))
PCA_res <- prcomp(df_expo, scale. = TRUE)

# Extract the PCs that cumulatively explain at least 80% variance 
explained_variance <- summary(PCA_res)$importance[3,]
id_80var <- which.max(explained_variance >= 0.8)

df_sim_pca <- cbind(df_sim, PCA_res$x[, 1:id_80var])
```

```{webr-r}
set.seed(1211)
confounders_nm <- df_sim_pca %>% select(starts_with("c")) %>% colnames()
mediator_nm <- df_sim_pca %>% select(starts_with("m")) %>% colnames()
outcome_nm <- "y"

result <- PCA_medTest(data = df_sim_pca, 
                      nboot = 1000,
                      outcome_nm = outcome_nm,
                      mediator_nm = mediator_nm,  
                      confounders_nm = confounders_nm)
```



## Environmental Risk Score

### Necessary Functions

```{webr-r}
ers_Calc = function(data, exposure, outcome, covar = NULL,
                    lambda2.start = NULL, include_int = T,
                    method = 'ls', scaled = FALSE, nfolds = 5, seed = NULL, ...) {
  # require the needed pkgs
  pkgs <- c("dplyr", "gcdnet", "magrittr", "progress", "pbapply")
  suppressMessages(lapply(pkgs, require, character.only = T))
  
  x = data %>% dplyr::select(all_of(exposure)) %>% as.data.frame()
  y = data[[outcome]] %>% as.matrix() %>% as.numeric()
  
  confounders <- covar
  
  covar = data %>% dplyr::select(all_of(covar)) %>% as.data.frame()
  
  if(is.null(covar) == F){
    if(any(!complete.cases(x)) | any(!complete.cases(y)) | any(!complete.cases(covar))){
      stop('x, y, or covar contain missing values. This method requires complete data.')
    }
  } else{
    if(any(!complete.cases(x)) | any(!complete.cases(y))) {
      stop('x, y, or covar contain missing values. This method requires complete data.')
    }
  }
  
  n = length(y)
  
  if(is.null(covar) == F){
    if(nrow(x) != n | nrow(covar) != n) {
      stop('y is not the same length as x or covar. y should be a vector of same 
         length as the number of rows in x and covar.')
    }
  } else{
    if(nrow(x) != n) {
      stop('y is not the same length as x or covar. y should be a vector of same 
         length as the number of rows in x and covar.')
    }
  }
  
  if(!is.null(seed)) { set.seed(seed) }
  if(is.null(lambda2.start)) {
    # auto-generate lambda2.start sequence.
  }
  
  foldid = matrix(data = c(sample(n), rep(1:nfolds, length = n)), nrow = n, ncol = 2)
  foldid = foldid[order(foldid[,1]),]
  foldid = foldid[,2]
  
  if(include_int == T){
    # the complex case where the interactions, square terms are in the ENET var selection
    data.mod = model.matrix(~-1+.^2, data = x)
    x.sq = x^2
    names(x.sq) = paste0(names(x), '^2')
    
    if(is.null(covar) == F){
      pf = c(rep(1, ncol(data.mod) + ncol(x.sq)), rep(0, ncol(covar))) 
      data.mod = cbind(data.mod, x.sq, covar)
      
      tmp_data = data.mod
      
      if(!isTRUE(scaled)) { data.mod = as.matrix(scale(data.mod, center = TRUE, scale = TRUE)) }
      
      pf2 = c(rep(1, ncol(data.mod)))
    } else {
      pf = c(rep(1, ncol(data.mod) + ncol(x.sq))) 
      data.mod = cbind(data.mod, x.sq)
      
      tmp_data = data.mod
      
      if(!isTRUE(scaled)) { data.mod = as.matrix(scale(data.mod, center = TRUE, scale = TRUE)) }
      
      pf2 = c(rep(1, ncol(data.mod)))
    }
    
  } else {
    # the simple case with just the original exposures
    data.mod = model.matrix(~-1+., data = x)
    
    if(is.null(covar) == F){
      pf = c(rep(1, ncol(data.mod)), rep(0, ncol(covar))) 
      data.mod = cbind(data.mod, covar)
      
      tmp_data = data.mod
      
      if(!isTRUE(scaled)) { data.mod = as.matrix(scale(data.mod, center = TRUE, scale = TRUE)) }
      
      pf2 = c(rep(1, ncol(data.mod)))
    } else {
      pf = c(rep(1, ncol(data.mod))) 
      data.mod = cbind(data.mod)
      
      tmp_data = data.mod
      
      if(!isTRUE(scaled)) { data.mod = as.matrix(scale(data.mod, center = TRUE, scale = TRUE)) }
      
      pf2 = c(rep(1, ncol(data.mod)))
    }
  }
  
  # ordinary Elastic net 
  ers.fit = ers.enet_adapt(data.mod, y, lambda2.start, nfolds, foldid, pf, pf2, method, ncol(covar))
  
  ers.beta = as.matrix(coef(ers.fit))
  ers.beta.keep = ers.beta != 0
  tab = matrix(0, sum(ers.beta.keep), 1)
  rownames(tab) = rownames(ers.beta)[ers.beta.keep]
  tab[,1] = ers.beta[ers.beta.keep,]
  
  if(is.null(covar) == F){
    tab.exposure = subset(tab, !(row.names(tab) %in% c('(Intercept)', colnames(covar))))
  } else {
    tab.exposure = subset(tab, !(row.names(tab) %in% c('(Intercept)')))
  }
  
  
  coef = as.numeric(tab.exposure)
  dat.score = as.matrix(data.mod[,rownames(tab.exposure)])
  
  # calculate the ERS score for each observation
  ers.scores = ers.score_adapt(data = dat.score, coef = coef)
  
  if(is.null(covar) == F){
    tmp_data_noExpo = data %>% dplyr::select(!all_of(exposure)) %>% dplyr::select(!all_of(confounders))
  } else {
    tmp_data_noExpo = data %>% dplyr::select(!all_of(exposure))
  }
  
  
  tmp_data = cbind(tmp_data_noExpo, tmp_data, ers.scores)
  
  ers.obj = list(
    post_ERS_data = tmp_data,
    ers.scores = ers.scores, # constructed ERS score 
    ers.fit = ers.fit, # ENET result of Y ~ expanded X
    coef = coef, # Coefficients of ENET
    dat.score = dat.score # data with non-zero effects after ENET
  )
  class(ers.obj) = 'ers'
  
  return(ers.obj)
}
```

```{webr-r}
ers.enet_adapt = function(x, y,
                          lambda2, nfolds = 5, foldid,
                          pf = rep(1, p), pf2 = rep(1, p),
                          method = 'ls', n_confound) {
  
  # a Function to format elapsed time
  format_elapsed_time <- function(elapsed_time) {
    if (elapsed_time < 60) {
      return(paste(elapsed_time, "seconds"))
    } else if (elapsed_time < 3600) {
      return(paste(round(elapsed_time / 60, 2), "minutes"))
    } else {
      return(paste(round(elapsed_time / 3600, 2), "hours"))
    }
  }
  
  # a function to count the number of selected variables
  count_selected_expos = function(model, n_confound) {
    sum(gcdnet::coef(model) != 0)  - n_confound -1 # for the intercept
  }
  
  # Start time
  start_time <- Sys.time()
  
  # 5 fold CV Elastic Net over the range of lambda2 
  cv.lambda2 = pbvapply(lambda2, function(lambda) {
    min(cv.gcdnet(x = x, y = y,
                  lambda2 = lambda, nfolds = nfolds, 
                  foldid = foldid, pf = pf, pf2 = pf2,
                  method = method)$cvm)
  }, FUN.VALUE = numeric(1))
  
  # Find the Optimal lambda2 and lambda1
  cv.lambda2.min = lambda2[which.min(cv.lambda2)]
  cv.lambda1.min = cv.gcdnet(x = x, y = y,
                             lambda2 = cv.lambda2.min,
                             nfolds = nfolds, foldid = foldid, 
                             method = method,
                             pf = pf, pf2 = pf2)$lambda.min
  
  
  best_mod <- gcdnet(x = x, y = y,
                     lambda = cv.lambda1.min,
                     lambda2 = cv.lambda2.min, 
                     pf = pf, pf2 = pf2,
                     method = method)
  
  
  if(count_selected_expos(best_mod, n_confound) < 3){
    # Case when optimal lambda1 and lambda2 select less than 3 exposures
    
    print(paste("The optimal Lambda 1 and Lambda 2 selects only", count_selected_expos(best_mod, n_confound), "exposures"))
    print(paste("The cv.lambda1.min is", cv.lambda1.min))
    print(paste("The cv.lambda2.min is", cv.lambda2.min))
    print("Loop all possible lambda 1 values to select at least 3 exposures")
    
    # Find the Optimal lambda1 that selects at least 3 exposures
    cv_result = cv.gcdnet(x = x, y = y,
                          lambda2 = cv.lambda2.min,
                          nfolds = nfolds, foldid = foldid,
                          method = method,
                          pf = pf, pf2 = pf2)
    
    lambda1_values = cv_result$lambda
    optimal_lambda1 = cv_result$lambda.min
    
    # Initialize progress bar
    pb <- progress_bar$new(
      format = "  Finding optimal lambda 1 values [:bar] :percent eta: :eta",
      total = length(lambda1_values),
      clear = FALSE,
      width = 60
    )
    
    for (lambda1 in lambda1_values) {
      model = gcdnet(x = x, y = y,
                     lambda = lambda1,
                     lambda2 = cv.lambda2.min,
                     pf = pf, pf2 = pf2, 
                     method = method)
      pb$tick()  # Update progress bar
      
      if (count_selected_expos(model, n_confound) >= 3) {
        optimal_lambda1 = lambda1
        break
      }
    }
    
    if (is.null(optimal_lambda1)) {
      # stop("No combination of lambda1 and lambda2 found that selects at least three exposures")
      
      print("No combination of lambda1 and lambda2 found that selects at least 3 exposures. Return the best model that minimizes least square error.")
      
      
      # End time
      end_time <- Sys.time()
      elapsed_seconds <- as.numeric(difftime(end_time, start_time, units = "secs"))
      print(paste("Elapsed time:", format_elapsed_time(elapsed_seconds)))
      
      # If no combination selects at least 3 exposures, use the minimum cross-validated lambda1
      
      return(best_mod)
    } else{
      print(paste("The optimal Lambda 1 value is now", optimal_lambda1))
      print(paste("The optimal Lambda 2 value is now", cv.lambda2.min))
      
      mod_atleast_3 <- gcdnet(x = x, y = y,
                              lambda = optimal_lambda1,
                              lambda2 = cv.lambda2.min,
                              pf = pf, pf2 = pf2,
                              method = method)
      
      print(paste("The chosen Lambda 1 and Lambda 2 now selects", count_selected_expos(mod_atleast_3, n_confound), "exposures"))
      
      # End time
      end_time <- Sys.time()
      elapsed_seconds <- as.numeric(difftime(end_time, start_time, units = "secs"))
      print(paste("Elapsed time:", format_elapsed_time(elapsed_seconds)))
      
      # return the best model with at least three variables chosen
      return(mod_atleast_3)
    }
    
  } else{
    # Case when optimal lambda1 and lambda2 select more than 3 exposures at first try
    print(paste("The optimal Lambda 1 and Lambda 2 selects", count_selected_expos(best_mod, n_confound), "exposures"))
    
    # End time
    end_time <- Sys.time()
    elapsed_seconds <- as.numeric(difftime(end_time, start_time, units = "secs"))
    print(paste("Elapsed time:", format_elapsed_time(elapsed_seconds)))
    
    # Return the Elastic Net results with optimal lambda settings
    return(best_mod)
  }
}
```

```{webr-r}
ers.score_adapt = function(data, coef) {
  score = data %*% coef
  colnames(score) = 'ERS'
  return(score)
}
```


### Run Necessary Functions

```{webr-r}
## Main Effects only
ERS_res_simple <- ers_Calc(data = df_sim,
                           exposure = paste0("x", 1:30),
                           outcome = "y",
                           covar = paste0("c", 1:5),
                           include_int = F,
                           lambda2.start = exp(seq(log(1e-4),
                                                   log(1e2),
                                                   length.out = 100)),
                           seed = 1211)

df_ers_simple <- ERS_res_simple$post_ERS_data

## Main Effects and Interactions, Squared terms
# evaluated by changing “include_int = T” in ers_Calc() 
```

```{webr-r}
set.seed(1211)
result_simple <- cmest(data = df_ers_simple,
                       model = "rb", full = T, EMint = F,
                       yreg = glm(y ~ ERS + m1, family = gaussian,
                                  data = df_ers_simple),
                       mreg =  list(glm(m1 ~ ERS, family = gaussian,
                                        data = df_ers_simple)),
                       mval = list(1),
                       outcome = "y", exposure = "ERS",
                       mediator = "m1",
                       inference = "bootstrap",
                       nboot = 1000, boot.ci.type = "per")
```


## BKMR (Component-wise variable selection)

### Necessary Functions

```{webr-r}
library(bkmr)
```



### Run Necessary Functions

```{webr-r}
#### BKMR set up ###
set.seed(1211)
exposures_X <- df_sim %>% 
  dplyr::select(contains("x")) %>% as.matrix()

confounders_C <- df_sim %>% 
  dplyr::select(starts_with("c")) %>% as.matrix()

outcome_Y  <- df_sim$y
mediator_M  <- df_sim$m1
# we assume no effect modifiers
E.M <- NULL; E.Y <- NULL

# create the required matrices
Z.M <- cbind(exposures_X, E.M) # for Mediator model
Z.Y <- cbind(exposures_X, E.Y) # for TE model
Zm.Y <- cbind(Z.Y, mediator_M) # for Outcome model
```


```{webr-r}
# outcome model
fit.y <- kmbayes(y = outcome_Y, Z = Zm.Y, X = confounders_C,
                 iter = 10000, verbose = TRUE, varsel = TRUE,
                 control.params = list(lambda.jump = 0.45,
                                       r.jump1 = 2,
                                       r.jump2 = 0.025))
bkmr_mod <- list()
bkmr_mod[["Outcome model"]] <- fit.y
```

```{webr-r}
# TE Model var selection results
pips <- ExtractPIPs(bkmr_mod[["TE model"]])
```

```{webr-r}
# set the confounders mean level 
X.predict <- matrix(colMeans(confounders_C),nrow=1)
astar <- c(apply(exposures_X, 2, quantile, probs=0.25)) # ref level
a <- c(apply(exposures_X, 2, quantile, probs=0.75)) # comp level
sel <- seq(5000,10000,by=10) # iteration indices for inference

result_BKMR <- mediation.bkmr(a = a, astar = astar,
                              # effect modifiers
                              e.m = NULL, e.y = NULL,
                              fit.m = bkmr_mod[["Mediator model"]], 
                              fit.y = bkmr_mod[["Outcome model"]], 
                              fit.y.TE = bkmr_mod[["TE model"]], 
                              # mean C level for BKMR models
                              X.predict.M = X.predict, 
                              X.predict.Y = X.predict, 
                              # the quantile values of M for CDE(m) 
                              m.quant=c(0.1,.25, 0.5,0.75), 
                              alpha = 0.05, # 95% credible interval
                              sel = sel, seed = 1211, K=100) 
```


## BKMR (Hierarchical variable selection)

```{webr-r}
cor_mat <- cor(exposures_X, method = "pearson")
hc <- hclust(as.dist(1 - cor_mat))

# Plot the dendrogram
plot(dendextend::color_branches(hc, k = 3),
     main = "Hierarchical Clustering Dendrogram",
     xlab = "", sub = "", cex = 0.9)
groups <- cutree(hc, k = 3) 
```


```{webr-r}
# outcome model
fit_y_hier <- kmbayes(y = outcome_Y, Z = Zm.Y, X = confounders_C,
                      iter = 10000, verbose = TRUE, varsel = TRUE,
                      groups = c(groups, 4),
                      control.params = list(lambda.jump = 0.45 ,r.jump2 = 0.025))
bkmr_mod_hier <- list()
bkmr_mod_hier[["Outcome model"]] <- fit_y_hier
```




## Example: PROTECT data

## Individual exposure testing (without co-exposure)

```{webr-r}
# set up
expo_nm <- colnames(list_headZscore[["Exposures"]])
# remove intercept
confounders_nm <- colnames(list_headZscore[["Confounders"]])[-1] 
mediator_nm <- "LTE4"
outcome_nm <- colnames(list_headZscore[["Data"]])[1]

df_head <- list_headZscore[["Data"]]
# run mediation testing
result <- IndExpo_medTest_NV(data = df_head,
                             exposures_nm = expo_nm,
                             mediator_nm = mediator_nm,
                             outcome_nm = outcome_nm,
                             confounders_nm = confounders_nm,
                             nboot = 1000)
```


## Individual exposure testing (with co-exposure)

```{webr-r}
# set up
expo_nm <- colnames(list_headZscore[["Exposures"]])
# remove intercept
confounders_nm <- colnames(list_headZscore[["Confounders"]])[-1] 
mediator_nm <- "LTE4"
outcome_nm <- colnames(list_headZscore[["Data"]])[1]

df_head <- list_headZscore[["Data"]]
# run mediation testing
result <- IndExpo_medTest(data = df_head,
                          exposures_nm = expo_nm,
                          mediator_nm = mediator_nm,
                          outcome_nm = outcome_nm,
                          confounders_nm = confounders_nm,
                          nboot = 1000)
```


## Principal component analysis

```{webr-r}
## PCA generation 
PCA_res_headZscore <- prcomp(list_headZscore[["Exposures"]] %>%
                               as.data.frame(), scale. = TRUE)

explained_variance <- summary(PCA_res_headZscore)$importance[3,] 
(id_80var <- which.max(explained_variance >= 0.8))

list_headZscore[["PCA_Data"]] <- cbind(list_headZscore[["Data"]],
                                       PCA_res_headZscore$x[, 1:id_80var])
```


```{webr-r}
confounders_nm <- colnames(list_headZscore[["Confounders"]])[-1]
mediator_nm <- "LTE4"
outcome_nm <- colnames(list_headZscore[["Data"]])[1]

## Mediation Test on all PCs
res_PCA <- PCA_medTest(data = list_headZscore[["PCA_Data"]],
                       nboot = 1000,
                       outcome_nm = outcome_nm,
                       mediator_nm = mediator_nm,
                       confounders_nm = confounders_nm)
```



## Environmental Risk Score

```{webr-r}
expo_nm <- colnames(list_headZscore[["Exposures"]])
confounders_nm <- colnames(list_headZscore[["Confounders"]])[-1]
mediator_nm <- "LTE4"
outcome_nm <- colnames(list_headZscore[["Data"]])[1]

## calculate ERS (Main Effects Only) Score
prERS_simp <- ers_Calc(data = list_headZscore[["Data"]],
                       exposure = expo_nm, outcome = outcome_nm,
                       covar = confounders_nm, seed = 1211,
                       lambda2.start = exp(seq(log(1e-4), log(1e2),
                                               length.out = 100)),
                       include_int = F)

## calculate ERS (Main Effects and Interactions) Score
# follows a similar code as prERS_simp 
# with the argument include_int = T changed
```


## BKMR (Component-wise variable selection)

```{webr-r}
exposures_X <- list_headZscore[["Exposures"]] %>% as.matrix()
confounders_C <- list_headZscore[["Confounders"]] %>% 
  as.data.frame() %>% dplyr::select(-Intercept) %>% as.matrix() 
outcome_Y  <- list_headZscore[["Data"]]$HEADCIRCUMFERENCEZSCORE
mediator_M  <- list_headZscore[["Mediators"]][, "LTE4"]
E.M <- NULL; E.Y <- NULL # we assume no effect modifiers

Z.M <- cbind(exposures_X, E.M); Z.Y <- cbind(exposures_X, E.Y) 
Zm.Y <- cbind(Z.Y, mediator_M)

# outcome model
set.seed(1211)
fit_y_headZ <- kmbayes(y = outcome_Y, Z = Zm.Y, X = confounders_C,
                       iter = 50000, verbose = TRUE, varsel = TRUE,
                       control.params = list(lambda.jump = 1,
                                             r.jump1 = 0.0001,
                                             r.jump2 = 0.1)) 
```


## BKMR (Hierarchical variable selection)

```{webr-r}
set.seed(1211)
exposures_X <- list_headZscore[["Exposures"]] %>% as.matrix()
cor_mat <- cor(exposures_X, method = "spearman")

# hierarchical clustering
hc <- hclust(as.dist(1 - cor_mat))
plot(dendextend::color_branches(hc, k = 5),
     main = "Hierarchical Clustering Dendrogram",
     xlab = "", sub = "", cex = 0.9)

# Cut the tree to form k clusters
groups <- cutree(hc, k = 5) 
```



```{webr-r}
confounders_C <- list_headZscore[["Confounders"]] %>% 
  as.data.frame() %>% select(-Intercept) %>% as.matrix() 
outcome_Y  <- list_headZscore[["Data"]]$HEADCIRCUMFERENCEZSCORE
mediator_M  <- list_headZscore[["Mediators"]][, "LTE4"]

E.M <- NULL; E.Y <- NULL
Z.M <- cbind(exposures_X, E.M); Z.Y <- cbind(exposures_X, E.Y);
Zm.Y <- cbind(Z.Y, mediator_M)

# outcome model
fit_y_headZ_hier <- kmbayes(y = outcome_Y,
                            Z = Zm.Y, X = confounders_C,
                            iter = 50000, verbose = TRUE,
                            varsel = TRUE, groups = c(groups, 6),
                            control.params = list(lambda.jump = 1,
                                                  r.jump1 = 0.1,
                                                  r.jump2 = 0.1)) 
```


